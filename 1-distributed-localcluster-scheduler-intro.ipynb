{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d19f489-59e6-48c7-aade-25530dcf253c",
   "metadata": {},
   "source": [
    "# Dask clusters\n",
    "\n",
    "(the material is based on the notebook https://github.com/jrbourbeau/hacking-dask)\n",
    "\n",
    "This notebook covers Dask's distributed clusters in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6b992-283e-4bb6-ade6-f5d030b54199",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cluster overview\n",
    "\n",
    "In this section we'll discuss:\n",
    "\n",
    "1. The different components which make up a Dask cluster\n",
    "2. Survey different ways to launch a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45762cb-a5a2-4f7c-ae29-02f05c78ba89",
   "metadata": {},
   "source": [
    "![dask schedulers](img/dask-cluster.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105546e3-d563-4419-9e88-2d240acf39b8",
   "metadata": {},
   "source": [
    "### Components of a cluster\n",
    "\n",
    "A Dask cluster is composed of three different types of objects:\n",
    "\n",
    "1. **Scheduler**: A single, centralized scheduler process which responds to requests for computations, maintains relavant state about tasks and worker, and sends tasks to workers to be computed.\n",
    "2. **Workers**: One or more worker processes which compute tasks and store/serve their results.\n",
    "3. **Clients**: One or more client objects which are the user-facing entry point to interact with the cluster.\n",
    "\n",
    "A couple of notes about workers:\n",
    "\n",
    "- Each worker runs in its own Python process. Each worker Python process has its own `concurrent.futures.ThreadPoolExecutor` which is uses to compute tasks in parallel.\n",
    "- There's actually a fourth cluster object which is often not discussed: the **Nanny**. By default Dask workers are launched and managed by a separate nanny process. This separate process allows workers to restart themselves if you want to use the `Client.restart` method, or to restart workers automatically if they get above a certain memory limit threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd19a5-7646-4c9e-a7fd-cd8d603d1615",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Related Documentation\n",
    "\n",
    "- [Cluster architecture](https://distributed.dask.org/en/latest/#architecture)\n",
    "- [Journey of a task](https://distributed.dask.org/en/latest/journey.html)\n",
    "\n",
    "## Deploying Dask clusters\n",
    "\n",
    "Deploying a Dask cluster means launching scheduler, worker, and client processes and setting up the appropriate network connections so these processes can communicate with one another. Dask clusters can be lauched in a few different ways which we will discuss later.\n",
    "\n",
    "### Manual setup\n",
    "\n",
    "Launch a scheduler process using the `dask-scheduler` command line utility:\n",
    "\n",
    "```terminal\n",
    "$ dask-scheduler\n",
    "2023-07-20 20:42:29,894 - distributed.scheduler - INFO - -----------------------------------------------\n",
    "2023-07-20 20:42:30,432 - distributed.scheduler - INFO - State start\n",
    "2023-07-20 20:42:30,438 - distributed.scheduler - INFO - -----------------------------------------------\n",
    "2023-07-20 20:42:30,439 - distributed.scheduler - INFO - Clear task state\n",
    "2023-07-20 20:42:30,440 - distributed.scheduler - INFO -   Scheduler at: tcp://192.168.150.50:8786\n",
    "2023-07-20 20:42:30,440 - distributed.scheduler - INFO -   dashboard at:                     :8787\n",
    "2023-07-20 20:42:31,810 - distributed.scheduler - INFO - Register worker <WorkerState 'tls://oksana-2eshadura-40cern-2ech.dask-worker.coffea-opendata.casa:8788', name: kubernetes-worker-50d255ef-ba72-4162-af66-23fdbf942bb3, status: undefined, memory: 0, processing: 0>\n",
    "2023-07-20 20:42:31,813 - distributed.scheduler - INFO - Starting worker compute stream, tls://oksana-2eshadura-40cern-2ech.dask-worker.coffea-opendata.casa:8788\n",
    "2023-07-20 20:42:31,813 - distributed.core - INFO - Starting established connection\n",
    "```\n",
    "\n",
    "and then launch several workers by using the `dask-worker` command and providing them the address of the scheduler they should connect to:\n",
    "\n",
    "```terminal\n",
    "$ dask-worker tcp://192.0.0.100:8786\n",
    "2023-07-20 20:45:36,940 - distributed.worker - INFO -       Start worker at: tcp://192.168.150.50:38077\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -          Listening to: tcp://192.168.150.50:38077\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -          dashboard at:       192.168.150.50:34591\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO - Waiting to connect to:  tcp://192.168.150.50:8786\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO - -------------------------------------------------\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -               Threads:                        112\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -                Memory:                   4.00 GiB\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -       Local Directory: /home/cms-jovyan/dask-worker-space/worker-q_4j0zc5\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO - -------------------------------------------------\n",
    "2023-07-20 20:45:36,949 - distributed.worker - INFO -         Registered to:  tcp://192.168.150.50:8786\n",
    "2023-07-20 20:45:36,949 - distributed.worker - INFO - -------------------------------------------------\n",
    "2023-07-20 20:45:36,949 - distributed.core - INFO - Starting established connection\n",
    "                         \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd586767-878a-4442-ac67-dc8d80cbd987",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster managers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8031ac-58a0-40bb-a0b1-07847d54b964",
   "metadata": {},
   "source": [
    "Dask has the notion of cluster manager objects. Cluster managers offer a consistent interface for common activities like adding/removing workers to a cluster, retrieving logs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b97702-f747-4c5b-9404-364ec817ab82",
   "metadata": {},
   "source": [
    "![dask schedulers](img/dask-cluster-manager.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fbd0f-720a-48e2-aa07-fd9d9a01f381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import LocalCluster\n",
    "# Launch a scheduler and 4 workers on my local machine\n",
    "cluster = LocalCluster(n_workers=2, threads_per_worker=2)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41daa9b9-51c5-4996-85a5-144f19714389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale up to 10 workers\n",
    "cluster.scale(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8937b5b-2559-4eb1-96ae-d76b385526c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale down to 2 workers\n",
    "cluster.scale(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6098c3-1f8b-4e42-8d0a-996f2b44b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve cluster logs\n",
    "cluster.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350ead3-229a-4974-bd89-7174d99edbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down cluster\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94169465-79c0-4063-b7bf-dbc9264cdfe4",
   "metadata": {},
   "source": [
    "There are several projects in the Dask ecosystem for easily deploying clusters on commonly used computing resources:\n",
    "\n",
    "- [Dask-Jobqueue](https://jobqueue.dask.org/en/latest/) for deploying Dask on job queuing systems (e.g. PBS, Slurm, etc.)\n",
    "- [Dask-Kubernetes](https://kubernetes.dask.org/en/latest/) for deploying Dask using native Kubernetes APIs\n",
    "- [Dask-Cloudprovider](https://cloudprovider.dask.org/en/latest/) for deploying Dask clusters on various cloud platforms (e.g. AWS, GCP, Azure, etc.)\n",
    "- [Dask-Yarn](https://yarn.dask.org/en/latest/) for deploying Dask on YARN clusters\n",
    "- [Dask-MPI](http://mpi.dask.org/en/latest/) for deploying Dask on existing MPI environments\n",
    "\n",
    "Launching clusters with any of these projects follows a similar pattern as using Dask's built-in `LocalCluster`:\n",
    "\n",
    "```python\n",
    "\n",
    "# Launch a Dask cluster on a HTCondor job queueing system [For this you will need HTCondor related configurations]\n",
    "from dask_jobqueue import SLURMCluster\n",
    "cluster = SLURMCluster(...)\n",
    "\n",
    "\n",
    "# Launch a Dask cluster on a SLURM job queueing system [For this you will need SLURM related configurations]\n",
    "from dask_jobqueue import SLURMCluster\n",
    "cluster = SLURMCluster(...)\n",
    "\n",
    "\n",
    "# Launch a Dask cluster on a PBS job queueing system [For this you will need PBS related configurations]\n",
    "from dask_jobqueue import PBSCluster\n",
    "cluster = PBSCluster(...)\n",
    "\n",
    "# Launch a Dask cluster on a Kubernetes cluster [For this you will need Kubernetes related configurations]\n",
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(...)\n",
    "\n",
    "```\n",
    "\n",
    "#### Related Documentation\n",
    "\n",
    "- [Cluster setup](https://docs.dask.org/en/latest/setup.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dbabb8-709c-448f-bb35-d6f7c34c504a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
