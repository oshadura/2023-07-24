{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d19f489-59e6-48c7-aade-25530dcf253c",
   "metadata": {},
   "source": [
    "# Dask clusters\n",
    "\n",
    "(the material is based on the notebook https://github.com/jrbourbeau/hacking-dask)\n",
    "\n",
    "This notebook covers Dask's distributed clusters in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f83226c-4fe2-4b51-853e-fed3d4be2d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster overview\n",
    "\n",
    "In this section we'll discuss:\n",
    "\n",
    "1. The different components which make up a Dask cluster\n",
    "2. Survey different ways to launch a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45762cb-a5a2-4f7c-ae29-02f05c78ba89",
   "metadata": {},
   "source": [
    "<img src=\"img/dask-cluster.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105546e3-d563-4419-9e88-2d240acf39b8",
   "metadata": {},
   "source": [
    "### Components of a cluster\n",
    "\n",
    "A Dask cluster is composed of three different types of objects:\n",
    "\n",
    "1. **Scheduler**: A single, centralized scheduler process which responds to requests for computations, maintains relavant state about tasks and worker, and sends tasks to workers to be computed.\n",
    "2. **Workers**: One or more worker processes which compute tasks and store/serve their results.\n",
    "3. **Clients**: One or more client objects which are the user-facing entry point to interact with the cluster.\n",
    "\n",
    "A couple of notes about workers:\n",
    "\n",
    "- Each worker runs in its own Python process. Each worker Python process has its own `concurrent.futures.ThreadPoolExecutor` which is uses to compute tasks in parallel.\n",
    "- There's actually a fourth cluster object which is often not discussed: the **Nanny**. By default Dask workers are launched and managed by a separate nanny process. This separate process allows workers to restart themselves if you want to use the `Client.restart` method, or to restart workers automatically if they get above a certain memory limit threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd19a5-7646-4c9e-a7fd-cd8d603d1615",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Related Documentation\n",
    "\n",
    "- [Cluster architecture](https://distributed.dask.org/en/latest/#architecture)\n",
    "- [Journey of a task](https://distributed.dask.org/en/latest/journey.html)\n",
    "\n",
    "## Deploying Dask clusters\n",
    "\n",
    "Deploying a Dask cluster means launching scheduler, worker, and client processes and setting up the appropriate network connections so these processes can communicate with one another. Dask clusters can be lauched in a few different ways which we will discuss later.\n",
    "\n",
    "### Manual setup\n",
    "\n",
    "Launch a scheduler process using the `dask-scheduler` command line utility:\n",
    "\n",
    "```terminal\n",
    "$ dask-scheduler\n",
    "2023-07-20 20:42:29,894 - distributed.scheduler - INFO - -----------------------------------------------\n",
    "2023-07-20 20:42:30,432 - distributed.scheduler - INFO - State start\n",
    "2023-07-20 20:42:30,438 - distributed.scheduler - INFO - -----------------------------------------------\n",
    "2023-07-20 20:42:30,439 - distributed.scheduler - INFO - Clear task state\n",
    "2023-07-20 20:42:30,440 - distributed.scheduler - INFO -   Scheduler at: tcp://192.168.150.50:8786\n",
    "2023-07-20 20:42:30,440 - distributed.scheduler - INFO -   dashboard at:                     :8787\n",
    "2023-07-20 20:42:31,810 - distributed.scheduler - INFO - Register worker <WorkerState 'tls://oksana-2eshadura-40cern-2ech.dask-worker.coffea-opendata.casa:8788', name: kubernetes-worker-50d255ef-ba72-4162-af66-23fdbf942bb3, status: undefined, memory: 0, processing: 0>\n",
    "2023-07-20 20:42:31,813 - distributed.scheduler - INFO - Starting worker compute stream, tls://oksana-2eshadura-40cern-2ech.dask-worker.coffea-opendata.casa:8788\n",
    "2023-07-20 20:42:31,813 - distributed.core - INFO - Starting established connection\n",
    "```\n",
    "\n",
    "and then launch several workers by using the `dask-worker` command and providing them the address of the scheduler they should connect to:\n",
    "\n",
    "```terminal\n",
    "$ dask-worker tcp://192.0.0.100:8786\n",
    "2023-07-20 20:45:36,940 - distributed.worker - INFO -       Start worker at: tcp://192.168.150.50:38077\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -          Listening to: tcp://192.168.150.50:38077\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -          dashboard at:       192.168.150.50:34591\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO - Waiting to connect to:  tcp://192.168.150.50:8786\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO - -------------------------------------------------\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -               Threads:                        112\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -                Memory:                   4.00 GiB\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO -       Local Directory: /home/cms-jovyan/dask-worker-space/worker-q_4j0zc5\n",
    "2023-07-20 20:45:36,941 - distributed.worker - INFO - -------------------------------------------------\n",
    "2023-07-20 20:45:36,949 - distributed.worker - INFO -         Registered to:  tcp://192.168.150.50:8786\n",
    "2023-07-20 20:45:36,949 - distributed.worker - INFO - -------------------------------------------------\n",
    "2023-07-20 20:45:36,949 - distributed.core - INFO - Starting established connection\n",
    "                         \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd586767-878a-4442-ac67-dc8d80cbd987",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster managers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8031ac-58a0-40bb-a0b1-07847d54b964",
   "metadata": {},
   "source": [
    "Dask has the notion of cluster manager objects. Cluster managers offer a consistent interface for common activities like adding/removing workers to a cluster, retrieving logs, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b97702-f747-4c5b-9404-364ec817ab82",
   "metadata": {},
   "source": [
    "<img src=\"img/dask-cluster-manager.svg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa319cc-1221-4271-b05f-c5b110ed93b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dask LocalCluster\n",
    "\n",
    "LocalCluster creates a \"cluster\" of a scheduler and workers running on the local machine.\n",
    "\n",
    "Creating a cluster object will create a Dask scheduler and a number of Dask workers. If no arguments are specified then it will autodetect the number of CPU cores your system has and the amount of memory and create workers to appropriately fill that. You can also specify these arguments yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a77fbd0f-720a-48e2-aa07-fd9d9a01f381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-22' coro=<_wrap_awaitable() done, defined at /opt/conda/lib/python3.8/asyncio/tasks.py:688> exception=TypeError('TLS expects a `ssl_context` argument of type ssl.SSLContext (perhaps check your TLS configuration?) Instead got None')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/asyncio/tasks.py\", line 695, in _wrap_awaitable\n",
      "    return (yield from awaitable.__await__())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 309, in _\n",
      "    await self.start()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/nanny.py\", line 327, in start\n",
      "    await self.listen(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 455, in listen\n",
      "    listener = await listen(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/core.py\", line 366, in listen\n",
      "    return backend.get_listener(loc, handle_comm, deserialize, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 634, in get_listener\n",
      "    return self._listener_class(loc, handle_comm, deserialize, **connection_args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 504, in __init__\n",
      "    self.server_args = self._get_server_args(**connection_args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 608, in _get_server_args\n",
      "    ctx = _expect_tls_context(connection_args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 389, in _expect_tls_context\n",
      "    raise TypeError(\n",
      "TypeError: TLS expects a `ssl_context` argument of type ssl.SSLContext (perhaps check your TLS configuration?) Instead got None\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-21' coro=<_wrap_awaitable() done, defined at /opt/conda/lib/python3.8/asyncio/tasks.py:688> exception=TypeError('TLS expects a `ssl_context` argument of type ssl.SSLContext (perhaps check your TLS configuration?) Instead got None')>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/asyncio/tasks.py\", line 695, in _wrap_awaitable\n",
      "    return (yield from awaitable.__await__())\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 309, in _\n",
      "    await self.start()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/nanny.py\", line 327, in start\n",
      "    await self.listen(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 455, in listen\n",
      "    listener = await listen(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/core.py\", line 366, in listen\n",
      "    return backend.get_listener(loc, handle_comm, deserialize, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 634, in get_listener\n",
      "    return self._listener_class(loc, handle_comm, deserialize, **connection_args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 504, in __init__\n",
      "    self.server_args = self._get_server_args(**connection_args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 608, in _get_server_args\n",
      "    ctx = _expect_tls_context(connection_args)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 389, in _expect_tls_context\n",
      "    raise TypeError(\n",
      "TypeError: TLS expects a `ssl_context` argument of type ssl.SSLContext (perhaps check your TLS configuration?) Instead got None\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Status.init",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/deploy/spec.py:262\u001b[0m, in \u001b[0;36mSpecCluster.__init__\u001b[0;34m(self, workers, scheduler, worker, asynchronous, loop, security, silence_logs, name, shutdown_on_close, scheduler_sync_interval)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_correct_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py:318\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py:385\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py:358\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    357\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tornado/gen.py:769\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/deploy/spec.py:354\u001b[0m, in \u001b[0;36mSpecCluster._correct_state_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m         w\u001b[38;5;241m.\u001b[39m_cluster \u001b[38;5;241m=\u001b[39m weakref\u001b[38;5;241m.\u001b[39mref(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 354\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m w  \u001b[38;5;66;03m# for tornado gen.coroutine support\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(to_open, workers)))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/core.py:309\u001b[0m, in \u001b[0;36mServer.__await__.<locals>._\u001b[0;34m()\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m Status\u001b[38;5;241m.\u001b[39mrunning\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/nanny.py:327\u001b[0m, in \u001b[0;36mNanny.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlisten(\n\u001b[1;32m    328\u001b[0m         start_address, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecurity\u001b[38;5;241m.\u001b[39mget_listen_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworker\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    329\u001b[0m     )\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/core.py:455\u001b[0m, in \u001b[0;36mServer.listen\u001b[0;34m(self, port_or_addr, allow_offload, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(addr, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m--> 455\u001b[0m listener \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43maddr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_comm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeserialize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_offload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_offload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlisteners\u001b[38;5;241m.\u001b[39mappend(listener)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/comm/core.py:366\u001b[0m, in \u001b[0;36mlisten\u001b[0;34m(addr, handle_comm, deserialize, **kwargs)\u001b[0m\n\u001b[1;32m    364\u001b[0m backend \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mget_backend(scheme)\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_listener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_comm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py:634\u001b[0m, in \u001b[0;36mBaseTCPBackend.get_listener\u001b[0;34m(self, loc, handle_comm, deserialize, **connection_args)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_listener\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc, handle_comm, deserialize, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconnection_args):\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_listener_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_comm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeserialize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconnection_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py:504\u001b[0m, in \u001b[0;36mBaseTCPListener.__init__\u001b[0;34m(self, address, comm_handler, deserialize, allow_offload, default_host, default_port, **connection_args)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_offload \u001b[38;5;241m=\u001b[39m allow_offload\n\u001b[0;32m--> 504\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_server_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconnection_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtcp_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py:608\u001b[0m, in \u001b[0;36mTLSListener._get_server_args\u001b[0;34m(self, **connection_args)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_server_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconnection_args):\n\u001b[0;32m--> 608\u001b[0m     ctx \u001b[38;5;241m=\u001b[39m \u001b[43m_expect_tls_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: ctx}\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py:389\u001b[0m, in \u001b[0;36m_expect_tls_context\u001b[0;34m(connection_args)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ctx, ssl\u001b[38;5;241m.\u001b[39mSSLContext):\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLS expects a `ssl_context` argument of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl.SSLContext (perhaps check your TLS configuration?)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Instead got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mctx\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m     )\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ctx\n",
      "\u001b[0;31mTypeError\u001b[0m: TLS expects a `ssl_context` argument of type ssl.SSLContext (perhaps check your TLS configuration?) Instead got None",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalCluster\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Launch a scheduler and 4 workers on my local machine\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cluster \u001b[38;5;241m=\u001b[39m \u001b[43mLocalCluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads_per_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m cluster\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/deploy/local.py:236\u001b[0m, in \u001b[0;36mLocalCluster.__init__\u001b[0;34m(self, name, n_workers, threads_per_worker, processes, loop, start, host, ip, scheduler_port, silence_logs, dashboard_address, worker_dashboard_address, diagnostics_port, services, worker_services, service_kwargs, asynchronous, security, protocol, blocked_handlers, interface, worker_class, scheduler_kwargs, scheduler_sync_interval, **worker_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m worker \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m: worker_class, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptions\u001b[39m\u001b[38;5;124m\"\u001b[39m: worker_kwargs}\n\u001b[1;32m    234\u001b[0m workers \u001b[38;5;241m=\u001b[39m {i: worker \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_workers)}\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilence_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilence_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecurity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msecurity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_sync_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_sync_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/deploy/spec.py:264\u001b[0m, in \u001b[0;36mSpecCluster.__init__\u001b[0;34m(self, workers, scheduler, worker, asynchronous, loop, security, silence_logs, name, shutdown_on_close, scheduler_sync_interval)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_correct_state)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py:318\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py:385\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    384\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/utils.py:358\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    356\u001b[0m         future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mwait_for(future, callback_timeout)\n\u001b[1;32m    357\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 358\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     error \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tornado/gen.py:769\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    766\u001b[0m exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    771\u001b[0m     exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/deploy/spec.py:421\u001b[0m, in \u001b[0;36mSpecCluster._close\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created:\n\u001b[0;32m--> 421\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m w\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m Status\u001b[38;5;241m.\u001b[39mclosed, w\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_old_logging_level\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    424\u001b[0m     silence_logging(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_old_logging_level)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Status.init"
     ]
    }
   ],
   "source": [
    "from dask.distributed import LocalCluster\n",
    "# Launch a scheduler and 4 workers on my local machine\n",
    "cluster = LocalCluster(n_workers=2, threads_per_worker=2)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9007fd00-c304-4689-b10d-d83e33b8e380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mLocalCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthreads_per_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscheduler_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msilence_logs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdashboard_address\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m':8787'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworker_dashboard_address\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdiagnostics_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mservices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworker_services\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mservice_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msecurity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mblocked_handlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minterface\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mworker_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscheduler_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscheduler_sync_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mworker_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m        \n",
       "\u001b[0;32mclass\u001b[0m \u001b[0mLocalCluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpecCluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Create local Scheduler and Workers\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    This creates a \"cluster\" of a scheduler and workers running on the local\u001b[0m\n",
       "\u001b[0;34m    machine.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    n_workers: int\u001b[0m\n",
       "\u001b[0;34m        Number of workers to start\u001b[0m\n",
       "\u001b[0;34m    processes: bool\u001b[0m\n",
       "\u001b[0;34m        Whether to use processes (True) or threads (False).  Defaults to True, unless\u001b[0m\n",
       "\u001b[0;34m        worker_class=Worker, in which case it defaults to False.\u001b[0m\n",
       "\u001b[0;34m    threads_per_worker: int\u001b[0m\n",
       "\u001b[0;34m        Number of threads per each worker\u001b[0m\n",
       "\u001b[0;34m    scheduler_port: int\u001b[0m\n",
       "\u001b[0;34m        Port of the scheduler.  8786 by default, use 0 to choose a random port\u001b[0m\n",
       "\u001b[0;34m    silence_logs: logging level\u001b[0m\n",
       "\u001b[0;34m        Level of logs to print out to stdout.  ``logging.WARN`` by default.\u001b[0m\n",
       "\u001b[0;34m        Use a falsey value like False or None for no change.\u001b[0m\n",
       "\u001b[0;34m    host: string\u001b[0m\n",
       "\u001b[0;34m        Host address on which the scheduler will listen, defaults to only localhost\u001b[0m\n",
       "\u001b[0;34m    ip: string\u001b[0m\n",
       "\u001b[0;34m        Deprecated.  See ``host`` above.\u001b[0m\n",
       "\u001b[0;34m    dashboard_address: str\u001b[0m\n",
       "\u001b[0;34m        Address on which to listen for the Bokeh diagnostics server like\u001b[0m\n",
       "\u001b[0;34m        'localhost:8787' or '0.0.0.0:8787'.  Defaults to ':8787'.\u001b[0m\n",
       "\u001b[0;34m        Set to ``None`` to disable the dashboard.\u001b[0m\n",
       "\u001b[0;34m        Use ':0' for a random port.\u001b[0m\n",
       "\u001b[0;34m    worker_dashboard_address: str\u001b[0m\n",
       "\u001b[0;34m        Address on which to listen for the Bokeh worker diagnostics server like\u001b[0m\n",
       "\u001b[0;34m        'localhost:8787' or '0.0.0.0:8787'.  Defaults to None which disables the dashboard.\u001b[0m\n",
       "\u001b[0;34m        Use ':0' for a random port.\u001b[0m\n",
       "\u001b[0;34m    diagnostics_port: int\u001b[0m\n",
       "\u001b[0;34m        Deprecated.  See dashboard_address.\u001b[0m\n",
       "\u001b[0;34m    asynchronous: bool (False by default)\u001b[0m\n",
       "\u001b[0;34m        Set to True if using this cluster within async/await functions or within\u001b[0m\n",
       "\u001b[0;34m        Tornado gen.coroutines.  This should remain False for normal use.\u001b[0m\n",
       "\u001b[0;34m    blocked_handlers: List[str]\u001b[0m\n",
       "\u001b[0;34m        A list of strings specifying a blocklist of handlers to disallow on the\u001b[0m\n",
       "\u001b[0;34m        Scheduler, like ``['feed', 'run_function']``\u001b[0m\n",
       "\u001b[0;34m    service_kwargs: Dict[str, Dict]\u001b[0m\n",
       "\u001b[0;34m        Extra keywords to hand to the running services\u001b[0m\n",
       "\u001b[0;34m    security : Security or bool, optional\u001b[0m\n",
       "\u001b[0;34m        Configures communication security in this cluster. Can be a security\u001b[0m\n",
       "\u001b[0;34m        object, or True. If True, temporary self-signed credentials will\u001b[0m\n",
       "\u001b[0;34m        be created automatically.\u001b[0m\n",
       "\u001b[0;34m    protocol: str (optional)\u001b[0m\n",
       "\u001b[0;34m        Protocol to use like ``tcp://``, ``tls://``, ``inproc://``\u001b[0m\n",
       "\u001b[0;34m        This defaults to sensible choice given other keyword arguments like\u001b[0m\n",
       "\u001b[0;34m        ``processes`` and ``security``\u001b[0m\n",
       "\u001b[0;34m    interface: str (optional)\u001b[0m\n",
       "\u001b[0;34m        Network interface to use.  Defaults to lo/localhost\u001b[0m\n",
       "\u001b[0;34m    worker_class: Worker\u001b[0m\n",
       "\u001b[0;34m        Worker class used to instantiate workers from. Defaults to Worker if\u001b[0m\n",
       "\u001b[0;34m        processes=False and Nanny if processes=True or omitted.\u001b[0m\n",
       "\u001b[0;34m    **worker_kwargs:\u001b[0m\n",
       "\u001b[0;34m        Extra worker arguments. Any additional keyword arguments will be passed\u001b[0m\n",
       "\u001b[0;34m        to the ``Worker`` class constructor.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> cluster = LocalCluster()  # Create a local cluster  # doctest: +SKIP\u001b[0m\n",
       "\u001b[0;34m    >>> cluster  # doctest: +SKIP\u001b[0m\n",
       "\u001b[0;34m    LocalCluster(\"127.0.0.1:8786\", workers=8, threads=8)\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> c = Client(cluster)  # connect to local cluster  # doctest: +SKIP\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Scale the cluster to three workers\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> cluster.scale(3)  # doctest: +SKIP\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Pass extra keyword arguments to Bokeh\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> LocalCluster(service_kwargs={'dashboard': {'prefix': '/foo'}})  # doctest: +SKIP\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mn_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mthreads_per_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mscheduler_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msilence_logs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWARN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdashboard_address\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\":8787\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mworker_dashboard_address\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdiagnostics_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mservices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mworker_services\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mservice_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msecurity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mblocked_handlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minterface\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mworker_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mscheduler_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mscheduler_sync_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mworker_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mip\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# In the future we should warn users about this move\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# warnings.warn(\"The ip keyword has been moved to host\")\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdiagnostics_port\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"diagnostics_port has been deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Please use `dashboard_address=` instead\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mdashboard_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiagnostics_port\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mthreads_per_worker\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Setting `threads_per_worker` to 0 has been deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Please set to None or to a specific int.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mthreads_per_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"dashboard\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworker_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Setting `dashboard` is discouraged. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Please set `dashboard_address` to affect the scheduler (more common) \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"and `worker_dashboard_address` for the worker (less common).\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprocesses\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNanny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mworker_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mworker_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNanny\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprocesses\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mWorker\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0msecurity\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Falsey values load the default configuration\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msecurity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSecurity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0msecurity\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# True indicates self-signed temporary credentials should be used\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msecurity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSecurity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecurity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSecurity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"security must be a Security object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhost\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"://\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0msecurity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msecurity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_encryption\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"tls://\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocesses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mscheduler_port\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"inproc://\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"tcp://\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"://\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhost\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inproc\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minterface\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"127.0.0.1\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mservices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mservices\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mworker_services\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker_services\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_workers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthreads_per_worker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mn_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads_per_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnprocesses_nthreads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mn_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mthreads_per_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCPU_COUNT\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_workers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthreads_per_worker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mn_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCPU_COUNT\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mthreads_per_worker\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprocesses\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_workers\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthreads_per_worker\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;31m# Overcommit threads per worker, rather than undercommit\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mthreads_per_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPU_COUNT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mn_workers\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"memory_limit\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mworker_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mworker_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"memory_limit\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_memory_limit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mworker_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"host\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"nthreads\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthreads_per_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"services\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mworker_services\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"dashboard_address\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mworker_dashboard_address\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"dashboard\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mworker_dashboard_address\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"interface\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minterface\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"protocol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"security\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msecurity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"silence_logs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msilence_logs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mScheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"options\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtoolz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mservices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mservice_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0msecurity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecurity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler_port\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0minterface\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mdashboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdashboard_address\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mdashboard_address\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdashboard_address\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mblocked_handlers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocked_handlers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mscheduler_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mworker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"cls\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mworker_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"options\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mworker_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mworkers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mworker\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mworker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mloop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msilence_logs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msilence_logs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msecurity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecurity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mscheduler_sync_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler_sync_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mstart_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"The `cluster.start_worker` function has been removed. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m\"Please see the `cluster.scale` method instead.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcluster_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"local_cluster.html.j2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcluster_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_status\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr_html_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_status\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.8/site-packages/distributed/deploy/local.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dask.distributed import LocalCluster\n",
    "LocalCluster??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41daa9b9-51c5-4996-85a5-144f19714389",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Scale up to 3 workers\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcluster\u001b[49m\u001b[38;5;241m.\u001b[39mscale(\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster' is not defined"
     ]
    }
   ],
   "source": [
    "# Scale up to 3 workers\n",
    "cluster.scale(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8937b5b-2559-4eb1-96ae-d76b385526c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale down to 2 workers\n",
    "cluster.scale(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b6098c3-1f8b-4e42-8d0a-996f2b44b1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 03:48:18,893 - distributed.nanny - WARNING - Worker process still alive after 3.1999986267089846 seconds, killing\n",
      "2023-07-24 03:48:18,895 - distributed.nanny - WARNING - Worker process still alive after 3.1999990844726565 seconds, killing\n",
      "2023-07-24 03:48:18,987 - distributed.nanny - WARNING - Worker process still alive after 3.1999992370605472 seconds, killing\n",
      "2023-07-24 03:48:18,989 - distributed.nanny - WARNING - Worker process still alive after 3.1999990844726565 seconds, killing\n",
      "2023-07-24 03:48:18,991 - distributed.nanny - WARNING - Worker process still alive after 3.1999990844726565 seconds, killing\n",
      "2023-07-24 03:48:19,087 - distributed.nanny - WARNING - Worker process still alive after 3.1999992370605472 seconds, killing\n",
      "2023-07-24 03:48:19,090 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing\n",
      "2023-07-24 03:48:19,185 - distributed.nanny - WARNING - Worker process still alive after 3.199999389648438 seconds, killing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <details>\n",
       "    <summary style='display:list-item'>Cluster</summary>\n",
       "    \n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\"></p>\n",
       "    \n",
       "\n",
       "    </details>\n",
       "\n",
       "    <details>\n",
       "    <summary style='display:list-item'>Scheduler</summary>\n",
       "    \n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,787 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:38725&#x27;, name: 16, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170494.7878122&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,787 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:35451&#x27;, name: 15, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170494.7871118&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,786 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:42017&#x27;, name: 14, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170494.7863724&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,785 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:33717&#x27;, name: 13, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170494.7854922&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,692 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:41357&#x27;, name: 11, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170494.6922975&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,691 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:34563&#x27;, name: 12, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170494.691738&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,691 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:39327&#x27;, name: 9, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170494.6910913&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,690 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:45229&#x27;, name: 10, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170494.6898422&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,412 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35451</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,412 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:35451&#x27;, name: 15, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,411 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33717</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,410 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:33717&#x27;, name: 13, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,390 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41357</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,388 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:41357&#x27;, name: 11, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,387 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42017</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:14,386 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:42017&#x27;, name: 14, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:13,691 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38725</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:13,690 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:38725&#x27;, name: 16, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:13,688 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45229</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:13,687 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:45229&#x27;, name: 10, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:12,492 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34563</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:48:12,490 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:34563&#x27;, name: 12, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,787 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:46411&#x27;, name: 8, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170451.7875643&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,696 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:46599&#x27;, name: 7, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170451.6962333&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,592 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:38959&#x27;, name: 6, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170451.5926938&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,592 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:34163&#x27;, name: 5, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170451.5919805&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,591 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:43777&#x27;, name: 4, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170451.5912168&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,590 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:43973&#x27;, name: 3, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170451.59046&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,589 - distributed.scheduler - INFO - Remove worker &lt;WorkerState &#x27;tcp://127.0.0.1:44405&#x27;, name: 2, status: closing, memory: 0, processing: 0&gt; (stimulus_id=&#x27;handle-worker-cleanup-1690170451.5892582&#x27;)</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,320 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34163</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,320 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:34163&#x27;, name: 5, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,312 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43973</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,311 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:43973&#x27;, name: 3, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,305 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38959</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:31,304 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:38959&#x27;, name: 6, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:30,993 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44405</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:30,992 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:44405&#x27;, name: 2, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:30,886 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39327</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:30,885 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:39327&#x27;, name: 9, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:30,796 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46411</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:30,795 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:46411&#x27;, name: 8, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:27,792 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43777</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:27,791 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:43777&#x27;, name: 4, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:27,787 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46599</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:47:27,785 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:46599&#x27;, name: 7, status: closed, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:08,454 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44425</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:08,454 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:44425&#x27;, name: 1, status: running, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:08,452 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42269</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:07,727 - distributed.scheduler - INFO - Register worker &lt;WorkerState &#x27;tcp://127.0.0.1:42269&#x27;, name: 0, status: running, memory: 0, processing: 0&gt;</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:02,452 - distributed.scheduler - INFO -   dashboard at:  http://127.0.0.1:8787/status</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:02,451 - distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:38693</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:02,443 - distributed.scheduler - INFO - State start</p>\n",
       "    \n",
       "\n",
       "    </details>\n",
       "\n",
       "    <details>\n",
       "    <summary style='display:list-item'>tcp://127.0.0.1:42269</summary>\n",
       "    \n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:08,455 - distributed.worker - INFO - -------------------------------------------------</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:08,455 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38693</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:08,454 - distributed.worker - INFO - Starting Worker plugin shuffle</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO - -------------------------------------------------</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y7ho0gj5</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO -                Memory:                   2.00 GiB</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO -               Threads:                          2</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO - -------------------------------------------------</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38693</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33675</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO -           Worker name:                          0</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42269</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,099 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42269</p>\n",
       "    \n",
       "\n",
       "    </details>\n",
       "\n",
       "    <details>\n",
       "    <summary style='display:list-item'>tcp://127.0.0.1:44425</summary>\n",
       "    \n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:08,457 - distributed.worker - INFO - -------------------------------------------------</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:08,457 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38693</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:08,456 - distributed.worker - INFO - Starting Worker plugin shuffle</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,111 - distributed.worker - INFO - -------------------------------------------------</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,110 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yqx4fysc</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,110 - distributed.worker - INFO -                Memory:                   2.00 GiB</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,110 - distributed.worker - INFO -               Threads:                          2</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,110 - distributed.worker - INFO - -------------------------------------------------</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,110 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38693</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,110 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43117</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,110 - distributed.worker - INFO -           Worker name:                          1</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,110 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44425</p>\n",
       "    \n",
       "\n",
       "    \n",
       "        <p style=\"font-family: monospace; margin: 0;\">2023-07-24 03:46:06,110 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44425</p>\n",
       "    \n",
       "\n",
       "    </details>\n"
      ],
      "text/plain": [
       "{'Cluster': '',\n",
       " 'Scheduler': \"2023-07-24 03:48:14,787 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38725', name: 16, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170494.7878122')\\n2023-07-24 03:48:14,787 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35451', name: 15, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170494.7871118')\\n2023-07-24 03:48:14,786 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42017', name: 14, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170494.7863724')\\n2023-07-24 03:48:14,785 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33717', name: 13, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170494.7854922')\\n2023-07-24 03:48:14,692 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41357', name: 11, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170494.6922975')\\n2023-07-24 03:48:14,691 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34563', name: 12, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170494.691738')\\n2023-07-24 03:48:14,691 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39327', name: 9, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170494.6910913')\\n2023-07-24 03:48:14,690 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45229', name: 10, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170494.6898422')\\n2023-07-24 03:48:14,412 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35451\\n2023-07-24 03:48:14,412 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35451', name: 15, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:48:14,411 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33717\\n2023-07-24 03:48:14,410 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33717', name: 13, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:48:14,390 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41357\\n2023-07-24 03:48:14,388 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41357', name: 11, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:48:14,387 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42017\\n2023-07-24 03:48:14,386 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42017', name: 14, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:48:13,691 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38725\\n2023-07-24 03:48:13,690 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38725', name: 16, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:48:13,688 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45229\\n2023-07-24 03:48:13,687 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45229', name: 10, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:48:12,492 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34563\\n2023-07-24 03:48:12,490 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34563', name: 12, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:47:31,787 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46411', name: 8, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170451.7875643')\\n2023-07-24 03:47:31,696 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46599', name: 7, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170451.6962333')\\n2023-07-24 03:47:31,592 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38959', name: 6, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170451.5926938')\\n2023-07-24 03:47:31,592 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34163', name: 5, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170451.5919805')\\n2023-07-24 03:47:31,591 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43777', name: 4, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170451.5912168')\\n2023-07-24 03:47:31,590 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43973', name: 3, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170451.59046')\\n2023-07-24 03:47:31,589 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44405', name: 2, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1690170451.5892582')\\n2023-07-24 03:47:31,320 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34163\\n2023-07-24 03:47:31,320 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34163', name: 5, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:47:31,312 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43973\\n2023-07-24 03:47:31,311 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43973', name: 3, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:47:31,305 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38959\\n2023-07-24 03:47:31,304 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38959', name: 6, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:47:30,993 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44405\\n2023-07-24 03:47:30,992 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44405', name: 2, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:47:30,886 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39327\\n2023-07-24 03:47:30,885 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39327', name: 9, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:47:30,796 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46411\\n2023-07-24 03:47:30,795 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46411', name: 8, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:47:27,792 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43777\\n2023-07-24 03:47:27,791 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43777', name: 4, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:47:27,787 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46599\\n2023-07-24 03:47:27,785 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46599', name: 7, status: closed, memory: 0, processing: 0>\\n2023-07-24 03:46:08,454 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44425\\n2023-07-24 03:46:08,454 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44425', name: 1, status: running, memory: 0, processing: 0>\\n2023-07-24 03:46:08,452 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42269\\n2023-07-24 03:46:07,727 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42269', name: 0, status: running, memory: 0, processing: 0>\\n2023-07-24 03:46:02,452 - distributed.scheduler - INFO -   dashboard at:  http://127.0.0.1:8787/status\\n2023-07-24 03:46:02,451 - distributed.scheduler - INFO -   Scheduler at:     tcp://127.0.0.1:38693\\n2023-07-24 03:46:02,443 - distributed.scheduler - INFO - State start\",\n",
       " 'tcp://127.0.0.1:42269': '2023-07-24 03:46:08,455 - distributed.worker - INFO - -------------------------------------------------\\n2023-07-24 03:46:08,455 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38693\\n2023-07-24 03:46:08,454 - distributed.worker - INFO - Starting Worker plugin shuffle\\n2023-07-24 03:46:06,099 - distributed.worker - INFO - -------------------------------------------------\\n2023-07-24 03:46:06,099 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-y7ho0gj5\\n2023-07-24 03:46:06,099 - distributed.worker - INFO -                Memory:                   2.00 GiB\\n2023-07-24 03:46:06,099 - distributed.worker - INFO -               Threads:                          2\\n2023-07-24 03:46:06,099 - distributed.worker - INFO - -------------------------------------------------\\n2023-07-24 03:46:06,099 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38693\\n2023-07-24 03:46:06,099 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33675\\n2023-07-24 03:46:06,099 - distributed.worker - INFO -           Worker name:                          0\\n2023-07-24 03:46:06,099 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42269\\n2023-07-24 03:46:06,099 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42269',\n",
       " 'tcp://127.0.0.1:44425': '2023-07-24 03:46:08,457 - distributed.worker - INFO - -------------------------------------------------\\n2023-07-24 03:46:08,457 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:38693\\n2023-07-24 03:46:08,456 - distributed.worker - INFO - Starting Worker plugin shuffle\\n2023-07-24 03:46:06,111 - distributed.worker - INFO - -------------------------------------------------\\n2023-07-24 03:46:06,110 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yqx4fysc\\n2023-07-24 03:46:06,110 - distributed.worker - INFO -                Memory:                   2.00 GiB\\n2023-07-24 03:46:06,110 - distributed.worker - INFO -               Threads:                          2\\n2023-07-24 03:46:06,110 - distributed.worker - INFO - -------------------------------------------------\\n2023-07-24 03:46:06,110 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:38693\\n2023-07-24 03:46:06,110 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43117\\n2023-07-24 03:46:06,110 - distributed.worker - INFO -           Worker name:                          1\\n2023-07-24 03:46:06,110 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44425\\n2023-07-24 03:46:06,110 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44425'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve cluster logs\n",
    "cluster.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e350ead3-229a-4974-bd89-7174d99edbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shut down cluster\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
